<!DOCTYPE HTML>
<html>

<head>
    <title>ManiWAV: Learning Robot Manipulation from In-the-Wild Audio-Visual Data</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=1000">
    <link rel="stylesheet" href="assets/css/main.css" />
    <link rel="icon" href="assets/audio-icon.jpg">

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-LS6L6LB7RX"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-LS6L6LB7RX');
    </script>

    <meta property="og:url" content="https://maniwav.github.io" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="ManiWAV: Learning Robot Manipulation from In-the-Wild Audio-Visual Data" />
    <meta property="og:description" content="" />


</head>

<body id="top">


    <!-- Main -->
    <div id="main"
        style="padding-bottom:1em; padding-top: 5em; width: 60em; max-width: 70em; margin-left: auto; margin-right: auto;">

        <section id="four">
            <div class="box alt" style="margin-bottom: 1em;">
                <div class="row 0% uniform" style="width: 100%; display: flex; justify-content: space-between;">
                    <!-- Stanford Logo -->
                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 20%">
                        <span class="image fit" style="margin-bottom: 0.5em; margin-top: 0.3em">
                            <img src="images/stanford_logo.png" alt="">
                        </span>
                    </div>
                    <!-- Columbia Logo -->
                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 22%">
                        <span class="image fit" style="margin-bottom: 0.5em; margin-top: 0.3em">
                            <img src="images/columbia_engineering_logo.svg" alt="">
                        </span>
                    </div>
                    <!-- TRI Logo -->
                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 22%">
                        <span class="image fit" style="margin-bottom: 0.5em; margin-top: 0.3em">
                            <img src="images/tri_logo_landscape.svg" alt="">
                        </span>
                    </div>
                    <!-- MIT Logo -->
                    <!-- <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 25%">
                        <span class="image fit" style="margin-bottom: 0.5em; margin-top: 0.3em">
                            <img src="images/mit_logo.svg" alt="">
                        </span>
                    </div> -->
                </div>
            </div>

            <h1 style="text-align: center; margin-bottom: 0; color: #e0218a; font-size: 300%">ManiWAV:</h1>
            <h2 style="text-align: center; white-space: nowrap; font-size: 200%">Learning Robot <span
                    style="color:#e0218a">Mani</span>pulation
                from In-the-<span style="color:#e0218a">W</span>ild <span style="color:#e0218a">A</span>udio-<span
                    style="color:#e0218a">V</span>isual Data</h2>
            
            <h2 style="text-align: center; margin-top: -1em; margin-bottom: 1.5em;">
                Conference on Robot Learning (CoRL) 2024
            </h2>

            <h3 style="text-align: center; margin-top: -1em; margin-bottom: -1em;">
                <span style="color: black"><a href="https://lzylucy.github.io/">Zeyi Liu<sup>1</sup></a> &nbsp&nbsp <a
                        href="https://cheng-chi.github.io/">Cheng Chi<sup>1,2</sup></a>
                    &nbsp&nbsp <a href="https://eacousineau.com/">Eric Cousineau<sup>3</sup></a> &nbsp&nbsp <a
                        href="https://naveenoid.wordpress.com/">Naveen Kuppuswamy<sup>3</sup></a> &nbsp&nbsp
                    <br>
                    <a href="https://www.benburchfiel.com/">Benjamin Burchfiel<sup>3</sup></a> &nbsp&nbsp <a
                        href="https://shurans.github.io/">Shuran Song<sup>1,2</sup></a> <br>
                </span>
                <!-- <p style="margin-top:0.25em;"> <span style="color: #8C1515">Stanford University</span> &nbsp&nbsp 
                    <span style="color: #557aa0">Columbia University</span> &nbsp&nbsp
                    <span style="color: #EB0A1E">Toyota Research Institute</span> </p> -->
                <p style="margin-top:0.25em;"><sup>1</sup>Stanford University &nbsp&nbsp&nbsp&nbsp <sup>2</sup>Columbia
                    University &nbsp&nbsp&nbsp&nbsp
                    <sup>3</sup>Toyota Research Institute
                </p>
            </h3>

            <div style="text-align:center; margin-bottom: 1em;">
                <div>
                    <!-- PDF Link. -->
                    <span>
                        <a href="https://arxiv.org/abs/2406.19464" class="button">
                            <span class="icon">
                                <i class="fa fa-file-pdf-o"></i>
                            </span>
                            <span>Paper</span>
                        </a>
                    </span>
                    <span>
                        <a href="https://youtu.be/SzHENLZ7_tc" class="button">
                            <span class="icon">
                                <i class="fa fa-youtube-play"></i>
                            </span>
                            <span>Video (YouTube)</span>
                        </a>
                    </span>
                    <!-- Code Link. -->
                    <span>
                        <a href="https://github.com/real-stanford/maniwav" class="button">
                            <span class="icon">
                                <i class="fa fa-github"></i>
                            </span>
                            <span>Code</span>
                        </a>
                    </span>
                    <!-- Dataset Link. -->
                    <span>
                        <a href="https://real.stanford.edu/maniwav" class="button">
                            <span class="icon">
                                <i class="fa fa-database"></i>
                            </span>
                            <span>Dataset</span>
                        </a>
                    </span>
                </div>
            </div>

            <div class="box alt" style="margin-bottom: 1em;">
                <div class="row 50% uniform" style="width: 100%; color: black;">
                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        Human Demonstration with Audio-Visual Feedback
                    </div>

                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        Robot Policy Rollout
                    </div>
                </div>
                <div class="row 50% uniform" style="width: 100%;">
                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        <span class="image fit">
                            <video controls autoplay muted loop style="width: 75%; height:75%; margin-left: 4%;">
                                <source src="videos/demo.mp4" type="video/mp4">
                            </video>
                        </span>
                        <!-- Dish Washing Data Collection-->
                    </div>

                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        <span class="image fit">
                            <video controls autoplay muted loop style="width: 100%;">
                                <source src="videos/itw_demos/white-pan-env1.mp4" type="video/mp4">
                            </video>
                            <!-- <div style="position: absolute; top: 2%; right: 1%">
                                    <p style="color: white; text-align: center; font-size: 2em">1x</p>
                                </div> -->
                        </span>
                        <!-- Dish Washing -->
                    </div>
                </div>
            </div>

            <p style="color: black;">Audio signals provide rich information for the robot interaction and object
                properties
                through contact. These information can surprisingly ease the learning of contact-rich robot manipulation
                skills, especially when the visual information alone is ambiguous or incomplete. However, the usage of
                audio
                data in robot manipulation has been constrained to teleoperated demonstrations collected by either
                attaching
                a microphone to the robot or object, which significantly limits its usage in robot learning pipelines.
                In
                this work, we introduce ManiWAV: an 'ear-in-hand' data collection device to collect in-the-wild human
                demonstrations with synchronous audio and visual feedback, and a corresponding policy interface to learn
                robot manipulation policy directly from the demonstrations. We demonstrate the capabilities of our
                system
                through four contact-rich manipulation tasks that require either passively sensing the contact events
                and
                modes, or actively sensing the object surface materials and states. In addition, we show that our system
                can
                generalize to unseen in-the-wild environments, by learning from diverse in-the-wild human
                demonstrations.
            </p>

            <hr>
            <h3>Technical Summary Video (4 min)</h3>
            <div style="text-align: center; justify-content: center; margin-bottom: 20px;">
                <video controls style="width: 80%" poster="videos/summary-thumbnail.png">
                    <source src="videos/summary.mp4" type="video/mp4">
                </video>
            </div>

            <hr>
            <h3>Capability Experiments</h3>
            <h4> (a) Wiping Whiteboard ðŸª§</h4>
            The robot is tasked to wipe a shape (e.g. heart, square) drawn on a whiteboard. The robot can start in any
            initial configuration above the whiteboard and grasp an eraser in parallel to the board. The main challenge
            of the task is that the robot needs to exert a reasonable amount of contact force on the whiteboard while
            moving the eraser along the shape.
            <!-- <div style="text-align: center; justify-content: center; margin-top:15px; margin-bottom: 20px;">
                <video controls style="width: 80%">
                    <source src="videos/tasks/wipe-summary-compressed.mp4" type="video/mp4">
                </video>
            </div> -->

            <div class="box alt" style="margin-top:1em; margin-bottom: 1em;">
                <h4 style="color:#e0218a">ManiWAV (unmute to hear the contact mic recording):</h4>
                <div class="row 50% uniform" style="width: 100%;">
                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        <span class="image fit" style="margin-bottom: 0.5em;">
                            <video controls autoplay loop muted playsinline style="width: 100%; margin-right: 5%;">
                                <source src="videos/tasks/wipe/ours.mp4" type="video/mp4">
                            </video>
                        </span>
                        In distribution
                    </div>

                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        <span class="image fit" style="margin-bottom: 0.5em;">
                            <video controls autoplay loop muted playsinline style="width: 100%; margin-right: 5%;">
                                <source src="videos/tasks/wipe/ours-shape.mp4" type="video/mp4">
                            </video>
                        </span>
                        Unseen shape (e.g. star)
                    </div>

                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        <span class="image fit" style="margin-bottom: 0.5em;">
                            <video controls autoplay loop muted playsinline style="width: 100%; margin-right: 5%;">
                                <source src="videos/tasks/wipe/ours-height.mp4" type="video/mp4">
                            </video>
                        </span>
                        Unseen table height
                    </div>

                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        <span class="image fit" style="margin-bottom: 0.5em;">
                            <video controls autoplay loop muted playsinline style="width: 100%; margin-right: 5%;">
                                <source src="videos/tasks/wipe/ours-eraser.mp4" type="video/mp4">
                            </video>
                        </span>
                        Unseen eraser
                    </div>
                </div>
            </div>

            <div class="box alt" style="margin-top:1em; margin-bottom: 1em;">
                <h4 style="color:#e0218a">Baselines:</h4>
                <div class="row 50% uniform" style="width: 100%;">
                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        <span class="image fit" style="margin-bottom: 0.5em;">
                            <video controls autoplay loop muted playsinline style="width: 100%; margin-right: 5%;">
                                <source src="videos/tasks/wipe/vision-float-1.mp4" type="video/mp4">
                            </video>
                        </span>
                        Vision only: Eraser fails to get into contact with the whiteboard and <span
                            style="color:red">floats</span>.
                    </div>

                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        <span class="image fit" style="margin-bottom: 0.5em;">
                            <video controls autoplay loop muted playsinline style="width: 100%; margin-right: 5%;">
                                <source src="videos/tasks/wipe/vision-float-2.mp4" type="video/mp4">
                            </video>
                        </span>
                        Vision only: Eraser does not get into contact with the whiteboard and <span
                            style="color:red">floats</span>.
                    </div>

                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        <span class="image fit" style="margin-bottom: 0.5em;">
                            <video controls autoplay loop muted playsinline style="width: 100%; margin-right: 5%;">
                                <source src="videos/tasks/wipe/mlp-1.mp4" type="video/mp4">
                            </video>
                        </span>
                        MLP fusion: Policy <span style="color:red">terminates early</span> before shape is completely
                        wiped off.
                    </div>

                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        <span class="image fit" style="margin-bottom: 0.5em;">
                            <video controls autoplay loop muted playsinline style="width: 100%; margin-right: 5%;">
                                <source src="videos/tasks/wipe/wo-aug-1.mp4" type="video/mp4">
                            </video>
                        </span>
                        No noise augmentation: Robot <span style="color:red">presses too hard</span> on the whiteboard,
                        causing gripper to bend.
                    </div>
                </div>
            </div>

            <p><span style="color:#e0218a">Key Findings:</span>
            <ul style="margin-top:-1.5em">
                <li>Incorporating contact audio as additional source of information improves robustness and
                    generalizability of the policy. </li>
                <li>Noise augmentation is an effective strategy to bridge audio domain gap between human collected data
                    and robot deployment data, and increase the system's robustness to out-of-distribution sounds. </li>
                <li>Transformer encoder is better for fusing the vision and audio features comparing to using MLP
                    layers. </li>
            </ul>
            </p>
            <br>

            <h4> (b) Flipping Bagel ðŸ¥¯</h4>
            The robot is tasked to flip a bagel in a pan from facing down to facing upward using a spatula. To perform
            this task successfully, the robot needs to sense and switch between different contact modes -- precisely
            insert the spatula between the bagel and the pan, maintain the contact while sliding, and start to tilt up
            the spatula when the bagel is in contact with the edge of the pan.
            <!-- <div style="text-align: center; justify-content: center; margin-top:15px; margin-bottom: 20px;">
                <video controls style="width: 80%">
                    <source src="videos/tasks/flip-summary-compressed.mp4" type="video/mp4">
                </video>
            </div> -->

            <div class="box alt" style="margin-top:1em; margin-bottom: 1em;">
                <h4 style="color:#e0218a">ManiWAV (unmute to hear the contact mic recording):</h4>
                <div class="row 50% uniform" style="width: 100%;">
                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        <span class="image fit" style="margin-bottom: 0.5em;">
                            <video controls autoplay loop muted playsinline style="width: 100%; margin-right: 5%;">
                                <source src="videos/tasks/flip/ours-1.mp4" type="video/mp4">
                            </video>
                        </span>
                        In distribution
                    </div>

                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        <span class="image fit" style="margin-bottom: 0.5em;">
                            <video controls autoplay loop muted playsinline style="width: 100%; margin-right: 5%;">
                                <source src="videos/tasks/flip/ours-2.mp4" type="video/mp4">
                            </video>
                        </span>
                        In distribution
                    </div>

                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        <span class="image fit" style="margin-bottom: 0.5em;">
                            <video controls autoplay loop muted playsinline style="width: 100%; margin-right: 5%;">
                                <source src="videos/tasks/flip/ours-height.mp4" type="video/mp4">
                            </video>
                        </span>
                        Unseen table height
                    </div>

                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        <span class="image fit" style="margin-bottom: 0.5em;">
                            <video controls autoplay loop muted playsinline style="width: 100%; margin-right: 5%;">
                                <source src="videos/tasks/flip/ours-noise.mp4" type="video/mp4">
                            </video>
                        </span>
                        Noise perturbation
                    </div>
                </div>
            </div>

            <div class="box alt" style="margin-top:1em; margin-bottom: 1em;">
                <h4 style="color:#e0218a">Baselines:</h4>
                <div class="row 50% uniform" style="width: 100%;">
                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        <span class="image fit" style="margin-bottom: 0.5em;">
                            <video controls autoplay loop muted playsinline style="width: 100%; margin-right: 5%;">
                                <source src="videos/tasks/flip/vision-2.mp4" type="video/mp4">
                            </video>
                        </span>
                        Vision only: Spatula <span style="color:red">pokes</span> on the side of the bagel.
                    </div>

                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        <span class="image fit" style="margin-bottom: 0.5em;">
                            <video controls autoplay loop muted playsinline style="width: 100%; margin-right: 5%;">
                                <source src="videos/tasks/flip/vision-1.mp4" type="video/mp4">
                            </video>
                        </span>
                        Vision only: Robot <span style="color:red">loses contact</span> with the bagel before it's
                        flipped.
                    </div>

                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        <span class="image fit" style="margin-bottom: 0.5em;">
                            <video controls autoplay loop muted playsinline style="width: 100%; margin-right: 5%;">
                                <source src="videos/tasks/flip/resnet.mp4" type="video/mp4">
                            </video>
                        </span>
                        ResNet: Policy trained with a ResNet18 andio encoder fails due to <span
                            style="color:red">spatula displacement</span>.
                    </div>

                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        <span class="image fit" style="margin-bottom: 0.5em;">
                            <video controls autoplay loop muted playsinline style="width: 100%; margin-right: 5%;">
                                <source src="videos/tasks/flip/mlp-policy.mp4" type="video/mp4">
                            </video>
                        </span>
                        MLP policy: Using MLP instead of Diffusion Policy also sometimes <span style="color:red">loses contact</span> 
                        with the bagel before it's flipped.
                    </div>
                </div>
            </div>

            <div class="box alt" style="margin-bottom: 1em;">
                <h4 style="color:#e0218a">In-the-Wild Generalization:</h4>
                <div class="row 50% uniform" style="width: 100%;">
                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        <span class="image fit" style="margin-bottom: 0.5em;">
                            <video controls autoplay loop muted playsinline style="width: 100%; margin-right: 5%;">
                                <source src="videos/itw_demos/diff-bagel.mp4" type="video/mp4">
                            </video>
                        </span>
                        Different Bagels
                    </div>

                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        <span class="image fit" style="margin-bottom: 0.5em;">
                            <video controls autoplay loop muted playsinline style="width: 100%; margin-right: 5%;">
                                <source src="videos/itw_demos/black-pan-env1.mp4" type="video/mp4">
                            </video>
                        </span>
                        Different Pans
                    </div>
                </div>
            </div>
            <div class="box alt" style="margin-bottom: 1em;">
                <div class="row 50% uniform" style="width: 100%;">
                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        <span class="image fit" style="margin-bottom: 0.5em;">
                            <video controls autoplay loop muted playsinline style="width: 100%; margin-right: 5%;">
                                <source src="videos/itw_demos/white-pan-env1.mp4" type="video/mp4">
                            </video>
                        </span>
                        Different Pans
                    </div>

                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        <span class="image fit" style="margin-bottom: 0.5em;">
                            <video controls autoplay loop muted playsinline style="width: 100%; margin-right: 5%;">
                                <source src="videos/itw_demos/gray-pan-env2.mp4" type="video/mp4">
                            </video>
                        </span>
                        Different Environments
                    </div>
                </div>
            </div>

            <p><span style="color:#e0218a">Key Findings:</span>
            <ul style="margin-top:-1.5em">
                <li>Action diffusion yields better behavior comparing to MLP policy model. </li>
                <li>Training a transformer audio encoder from scratch yields better performance comparing to using a
                    CNN-based encoder. </li>
                <li>In-the-wild data enables generalization to unseen in-the-wild environments. </li>
            </ul>
            </p>

            <br>
            <h4> (c) Pouring ðŸŽ² </h4>
            The robot is tasked to pick up the white cup and pour dice out to the pink cup if the white cup is not
            empty.
            When finish pouring, the robot needs to place the empty cup down to a designated location.
            The challenge of the task is that the robot cannot observe whether there are dice in the cup or not given
            the
            camera view point both before and after the pouring action, therefore it needs to leverage feedback from
            vibrations of objects inside the cup. Watch the below <span style="color:#e0218a">video</span> for details
            of
            the task and ablations.
            <div style="text-align: center; justify-content: center; margin-top:15px; margin-bottom: 20px;">
                <video controls style="width: 80%">
                    <source src="videos/tasks/pour-summary-compressed.mp4" type="video/mp4">
                </video>
            </div>

            <br>
            <p><span style="color:#e0218a">Key Findings:</span>
            <ul style="margin-top:-1.5em">
                <li>Audio can provide critical state information beyond visual observations. </li>
                <li>Policy performance is sensitive to audio history length, either too short or too long will hurt
                    performance. </li>
            </ul>
            </p>

            <br>

            <h4> (d) Taping Wires with Velcro Tape âž° </h4>
            The robot is tasked to choose the 'hook' tape from several tapes (either 'hook' or 'loop') and strap wires
            by
            attaching the 'hook' tape to a 'loop' tape underneath the wires. The challenge of the task is that the
            difference between 'loop' and 'hook' tape are not observable with vision, but the subtle difference in
            surface
            material can generate different sounds when 'sliding' the gripper finger against the tape. Watch the below
            <span style="color:#e0218a">video</span> for details of the task and ablations.
            <div style="text-align: center; justify-content: center; margin-top:15px; margin-bottom: 20px;">
                <video controls style="width: 80%">
                    <source src="videos/tasks/tape-summary-compressed.mp4" type="video/mp4">
                </video>
            </div>

            <br>
            <p><span style="color:#e0218a">Key Findings:</span>
            <ul style="margin-top:-1.5em">
                <li>Contact microphone is sufficiently sensitive to different surface materials.</li>
                <li>Training-time noise augmentation is more effective than test-time noise reduction.</li>
            </ul>
            </p>

            <hr>
            <h3>More Results</h3>
            <h4>Attention Map Visualization</h4>
            <div class="box alt" style="margin-bottom: 1em;">
                <div class="row 50% uniform" style="width: 100%;">
                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%">
                        <span class="image fit" style="margin-bottom: 0.5em;">
                            <img src="images/audio_attention.png" alt="Description of Image">
                        </span>
                    </div>

                    <div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 50%;">
                        <p style="color:black; margin-top: 3em;">
                            Interestingly, we find that a policy co-trained with audio attends more on the
                            task-relevant regions (shape of drawing or free space inside the pan). In contrast, the
                            vision only policy often overfits to background structures as an shortcut to estimate
                            contact (e.g., the edge of the whiteboard, table, and room structures).
                        </p>
                    </div>
                </div>
            </div>

            <hr>
            <h3>Citation</h3>
                <pre><code style="color: black">@article{liu2024maniwav,
    title={ManiWAV: Learning Robot Manipulation from In-the-Wild Audio-Visual Data},
    author={Liu, Zeyi and Chi, Cheng and Cousineau, Eric and Kuppuswamy, Naveen and Burchfiel, Benjamin and Song, Shuran},
    journal={arXiv preprint arXiv:2406.19464},
    year={2024}
}</code></pre>

            <h3>Contact</h3>
            If you have any questions, please feel free to contact <a href="https://lzylucy.github.io/">Zeyi Liu</a>.
            <br><br>

            <h3>Acknowledgment</h3>
            The authors would like to thank Yifan Hou and Zhenjia Xu for their help with discussions and setup of
            real-world experiments, Karan Singh for assistance with audio visualization and data collection. In
            addition, we would like to thank all REALab members: Huy Ha, Mandi Zhao, Mengda Xu, Xiaomeng Xu, Chuer Pan,
            Austin Patel, Yihuai Gao, Haochen Shi, Dominik Bauer, Samir Gadre, et al. and additional collaborators at
            TRI: Siyuan Feng, Russ Tedrake for fruitful technical discussions and emotional support.
            The authors would also like to specially thank Xiaoran 'Van' Fan for his help with task brainstorm and audio
            expertise. This work was supported in part by the Toyota Research Institute, NSF Award #2143601, #2132519
            and Sloan Fellowship. The views and conclusions contained herein are those of the authors and should not be
            interpreted as necessarily representing the official policies, either expressed or implied, of the sponsors.
            <br><br>

    </div>

    <!-- Scripts -->
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/jquery.poptrox.min.js"></script>
    <script src="assets/js/skel.min.js"></script>
    <script src="assets/js/util.js"></script>
    <script src="assets/js/main.js"></script>
</body>

</html>